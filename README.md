Hi, I'm Eunjin Kim ğŸ‘‹ğŸ»
- I've mainly studied the analysis on Transformer-based PLM in terms of Linguistics and Attention Mechanism.
- Especially, I've deep-dived into prompt-tuning and p-tuning (soft-prompt).
- Currently, I'm also interested in LMOps!

### Experiences
ğŸ‘©ğŸ»â€ğŸ’» Working on Wrtn Technologies \
ğŸŒ± Learning LMOps \
ğŸ† Silver Prize on NIKL AI Language Language Ability Evaluation Contest

### Degrees
ğŸ¥ Master: Linguistics (Computational Linguistics) at Seoul National University \
ğŸ£ Bachelor: German Language and Literature & Digital Humanities Data Science at Seoul National University

### Publications
- ì´ìƒì•„, ê¹€ì„ê¸°, **ê¹€ì€ì§„**, ê°•ë¯¼ì§€, ì‹ íš¨í•„. 2022. í‚¤ì›Œë“œì™€ ë¬¸ì¥ ì„ë² ë”©ì„ í™œìš©í•œ ì¡°í•­ë³„ ë¶„ë¥˜ëª¨ë¸ ê¸°ë°˜ ê³„ì•½ì„œ ì ê²©ì„± ê²€ì¦. ì •ë³´ê³¼í•™íšŒë…¼ë¬¸ì§€, 49(10), 848-858.
- ì¥ë™ì¤€, **ê¹€ì€ì§„**, ì‹ íš¨í•„. (2022). Affinity Proberë¥¼ ì´ìš©í•œ ì–¸ì–´ ëª¨ë¸ì˜ ë¬¸ì¥ ìˆ˜ìš©ì„± íŒë‹¨ ê²°ì •ì˜ ê²½ê³„ ìš”ì¸ ë¶„ì„. ì–¸ì–´, 47(4), 829-855.
